{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4228102a-a94b-4e7c-8b34-6d7b7cd8dfd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latex table has been saved as 'samples_generated_table.tex'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31310/1958966879.py:78: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  multigpu_std = df_multigpu.groupby('worker_id').apply(calculate_samples_per_second).std()\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def read_worker_logs(directory):\n",
    "    data = []\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.startswith('worker') and filename.endswith('.log'):\n",
    "            with open(os.path.join(directory, filename), 'r') as f:\n",
    "                for line in f:\n",
    "                    timestamp, worker_id = line.strip().split(',')\n",
    "                    data.append({'timestamp': float(timestamp), 'worker_id': int(worker_id)})\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "def calculate_samples_per_second(df):\n",
    "    df = df.sort_values('timestamp')\n",
    "    total_time = df['timestamp'].max() - df['timestamp'].min()\n",
    "    total_samples = len(df)\n",
    "    samples_per_second = total_samples / total_time\n",
    "    return samples_per_second\n",
    "\n",
    "def create_latex_table(results, output_path):\n",
    "    latex_table = r\"\"\"\n",
    "\\begin{table}[h]\n",
    "\\centering\n",
    "\\begin{tabular}{lcccc}\n",
    "\\hline\n",
    "Experiment & Samples/sec & Speedup Factor\\\\\n",
    "\\hline\n",
    "\"\"\"\n",
    "    \n",
    "    baseline_samples = results['baseline']['samples_per_sec']\n",
    "    \n",
    "    for name, value in results.items():\n",
    "        speedup = value['samples_per_sec'] / baseline_samples\n",
    "        scaling = speedup / value['worker_count'] if value['worker_count'] > 0 else 1.0\n",
    "        latex_table += f\"{name} & {value['samples_per_sec']:.2f} $\\pm$ {value['std_dev']:.2f} & {speedup:.2f}x \\\\\\\\\\n\"\n",
    "    \n",
    "    latex_table += r\"\"\"\\hline\n",
    "\\end{tabular}\n",
    "\\caption{Samples Generated per Second, Speedup Factor}\n",
    "\\label{tab:samples_generated}\n",
    "\\end{table}\n",
    "\"\"\"\n",
    "    \n",
    "    with open(output_path, 'w') as f:\n",
    "        f.write(latex_table)\n",
    "\n",
    "# Read baseline data from previous experiment\n",
    "def read_baseline_data(csv_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    df['time'] = pd.to_datetime(df['time'], unit='s')\n",
    "    df = df.sort_values('time')\n",
    "    df['time_diff'] = df['time'].diff().dt.total_seconds()\n",
    "    df['samples_diff'] = df['samples_read'].diff()\n",
    "    df['samples_per_second'] = df['samples_diff'] / df['time_diff']\n",
    "    df = df.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "    return df['samples_per_second'].mean(), df['samples_per_second'].std()\n",
    "\n",
    "def process_wirehead_local(csv_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'], unit='s')\n",
    "    df = df.sort_values('timestamp')\n",
    "    df['time_diff'] = df['timestamp'].diff().dt.total_seconds()\n",
    "    df['samples_diff'] = df['sample'].diff()\n",
    "    df['samples_per_second'] = df['samples_diff'] / df['time_diff']\n",
    "    df = df.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "    return df['samples_per_second'].mean(), df['samples_per_second'].std()\n",
    "\n",
    "# Main execution\n",
    "baseline_path = 'baseline-2024-06-26_15-14/metrics.csv'\n",
    "multigpu_path = 'generator/1xgen/generator'\n",
    "\n",
    "baseline_avg, baseline_std = read_baseline_data(baseline_path)\n",
    "\n",
    "df_multigpu = read_worker_logs(multigpu_path)\n",
    "multigpu_avg = calculate_samples_per_second(df_multigpu)\n",
    "multigpu_std = df_multigpu.groupby('worker_id').apply(calculate_samples_per_second).std()\n",
    "\n",
    "# In the main execution section, add:\n",
    "wirehead_local_path = 'wirehead_train-2024-06-25_20-07/generator.csv'\n",
    "wirehead_local_avg, wirehead_local_std = process_wirehead_local(wirehead_local_path)\n",
    "\n",
    "# Update the results dictionary:\n",
    "\n",
    "\n",
    "results = {\n",
    "    'baseline': {\n",
    "        'samples_per_sec': baseline_avg,\n",
    "        'std_dev': baseline_std,\n",
    "        'worker_count': 1\n",
    "    },\n",
    "    'wirehead_local': {\n",
    "        'samples_per_sec': wirehead_local_avg,\n",
    "        'std_dev': wirehead_local_std,\n",
    "        'worker_count': 1\n",
    "    },\n",
    "    'wirehead_distributed': {\n",
    "        'samples_per_sec': multigpu_avg,\n",
    "        'std_dev': multigpu_std,\n",
    "        'worker_count': df_multigpu['worker_id'].nunique()\n",
    "    }\n",
    "}\n",
    "\n",
    "create_latex_table(results, 'svg/samples_generated_table.tex')\n",
    "\n",
    "print(\"Latex table has been saved as 'samples_generated_table.tex'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "30cc09ef-3b40-446f-b3ca-1f3fc4288365",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2512957848743425\n",
      "0.5000564480791648\n",
      "0.9832177906530393\n",
      "1.946361922288535\n",
      "3.944512843935724\n",
      "Latex table has been saved as 'samples_generated_table.tex'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def read_worker_logs(base_path, config):\n",
    "    directory = os.path.join(base_path, f\"{config}xgen\", \"generator\")\n",
    "    data = []\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.startswith('worker') and filename.endswith('.log'):\n",
    "            with open(os.path.join(directory, filename), 'r') as f:\n",
    "                for line in f:\n",
    "                    timestamp, worker_id = line.strip().split(',')\n",
    "                    data.append({'timestamp': float(timestamp), 'worker_id': int(worker_id)})\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "def calculate_samples_per_second(df):\n",
    "    df = df.sort_values('timestamp')\n",
    "    total_time = df['timestamp'].max() - df['timestamp'].min()\n",
    "    total_samples = len(df)\n",
    "    print(total_samples/ total_time)\n",
    "    return total_samples / total_time\n",
    "\n",
    "def process_configuration(base_path, config):\n",
    "    df = read_worker_logs(base_path, config)\n",
    "    samples_per_second = calculate_samples_per_second(df)\n",
    "    worker_count = df['worker_id'].nunique()\n",
    "    return samples_per_second, worker_count\n",
    "\n",
    "def create_latex_table(results, output_path):\n",
    "    latex_table = r\"\"\"\n",
    "\\begin{table}[h]\n",
    "\\centering\n",
    "\\begin{tabular}{lccc}\n",
    "\\hline\n",
    "Experiment & Workers & Samples/sec & Scaling Factor \\\\\n",
    "\\hline\n",
    "\"\"\"\n",
    "    \n",
    "    baseline_samples = results['1x wirehead generator']['samples_per_sec']\n",
    "    \n",
    "    for name, value in results.items():\n",
    "        scaling_factor = value['samples_per_sec'] / baseline_samples\n",
    "        latex_table += f\"{name} & {value['worker_count']} & {value['samples_per_sec']:.2f} & {scaling_factor:.2f} \\\\\\\\\\n\"\n",
    "    \n",
    "    latex_table += r\"\"\"\\hline\n",
    "\\end{tabular}\n",
    "\\caption{Samples Generated per Second, Worker Count, and Scaling Factor for Each Experiment}\n",
    "\\label{tab:samples_generated}\n",
    "\\end{table}\n",
    "\"\"\"\n",
    "    \n",
    "    with open(output_path, 'w') as f:\n",
    "        f.write(latex_table)\n",
    "\n",
    "# Main execution\n",
    "base_path = 'generator'\n",
    "configurations = [1, 2, 4, 8, 16]\n",
    "\n",
    "results = {}\n",
    "\n",
    "for config in configurations:\n",
    "    samples_per_second, worker_count = process_configuration(base_path, config)\n",
    "    results[f'{config}x wirehead generator'] = {\n",
    "        'samples_per_sec': samples_per_second,\n",
    "        'worker_count': worker_count\n",
    "    }\n",
    "\n",
    "create_latex_table(results, 'svg/scaling_samples_generated_table.tex')\n",
    "print(\"Latex table has been saved as 'samples_generated_table.tex'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
